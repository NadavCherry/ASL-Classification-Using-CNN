# ASL-Classification-Using-CNN

This project delves into the realm of American Sign Language (ASL) Alphabet Classification using Convolutional Neural Networks (CNNs). ASL, a vital visual language within the Deaf and hard-of-hearing community, serves as a unique mode of communication. In computer vision and artificial intelligence, recognizing ASL gestures holds great significance. This endeavor's primary goal is to harness deep learning's capabilities, specifically CNNs, to build a model adept at precisely identifying and classifying the distinctive hand gestures that represent each letter of the English alphabet in ASL. This project demonstrates the prowess of advanced technologies and contributes to fostering communication and accessibility for the Deaf community. By exploring the complexities of image recognition, our work endeavors to bridge the gap between computer vision and the intricate nature of sign language. We anticipate that this project will positively impact the field of assistive technology, steering us toward a future that is more inclusive and accessible.

![image](https://github.com/user-attachments/assets/07da6432-2536-470e-b796-a5c9c7e21c97)
